//! src/config.rs

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::PathBuf;
use tokio::fs;
use tokio::io::AsyncWriteExt;

use crate::llm::LLM;

/// FactoryåŠŸèƒ½ï¼Œæ ¹æ®é…ç½®è·å–LLMå®¢æˆ·ç«¯ã€‚
pub async fn get_llm_client() -> Result<LLM> {
    let config = load_config().await?;
    crate::llm::create_llm_client(&config)
}

/// Returns the configuration directory path (~/.config/matecode).
pub async fn get_config_dir() -> Result<PathBuf> {
    let config_dir = if cfg!(windows) {
        // Windows: %APPDATA%\matecode
        dirs::data_dir()
            .map(|p| p.join("matecode"))
            .context("Could not get data directory")?
    } else {
        // Linux/macOS: ~/.config/matecode
        dirs::config_dir()
            .map(|p| p.join("matecode"))
            .context("Could not get config directory")?
    };

    if !config_dir.exists() {
        fs::create_dir_all(&config_dir)
            .await
            .context("Could not create config directory")?;
    }
    Ok(config_dir)
}

/// Represents the main configuration for the application.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Config {
    /// The default LLM provider.
    pub provider: String,
    /// Language for prompts and UI
    pub language: String,
    /// LLM provider settings.
    pub llm: LLMProviders,
}

/// Defines the context window configuration for different models.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ModelConfig {
    /// The maximum number of tokens to use for the context.
    pub max_tokens: usize,
    /// The maximum number of tokens for the output.
    pub max_output_tokens: usize,
    /// Reserved tokens for system prompt and other overhead.
    pub reserved_tokens: usize,
}

/// Defines all LLM providers and their configurations.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct LLMProviders {
    pub openai: Option<OpenAIProvider>,
    pub gemini: Option<GeminiProvider>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct OpenAIProvider {
    pub api_key: String,
    pub api_base: Option<String>,
    pub models: HashMap<String, ModelConfig>,
    pub default_model: String,
    pub proxy: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct GeminiProvider {
    pub api_key: String,
    pub models: HashMap<String, ModelConfig>,
    pub default_model: String,
    pub proxy: Option<String>,
}

/// Creates a default configuration file and directory structure.
pub async fn create_default_config() -> Result<()> {
    let config_dir = get_config_dir().await?;
    let config_path = config_dir.join("config.toml");
    
    // Create prompts directory
    let prompts_dir = config_dir.join("prompts");
    if !prompts_dir.exists() {
        fs::create_dir_all(&prompts_dir).await?;
    }

    // åªåœ¨é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ‰åˆ›å»º
    if !config_path.exists() {
        // åªä¿ç•™å¿…è¦çš„æ¨¡å‹é…ç½®
        let mut openai_models = HashMap::new();
        
        // ç§æœ‰åŒ–éƒ¨ç½²æ¨¡å‹çš„é€šç”¨é…ç½®
        openai_models.insert("default".to_string(), ModelConfig {
            max_tokens: 32_768,      // å¤§å¤šæ•°ç§æœ‰åŒ–æ¨¡å‹çš„å¸¸è§é…ç½®
            max_output_tokens: 4_096,
            reserved_tokens: 1_000,
        });

        let mut gemini_models = HashMap::new();
        
        // Gemini 2.5 Flash é…ç½®
        gemini_models.insert("gemini-2.0-flash-exp".to_string(), ModelConfig {
            max_tokens: 1_048_576,   // Gemini 2.5 Flash çš„å®é™…å‚æ•°
            max_output_tokens: 8_192,
            reserved_tokens: 2_000,
        });

        let default_config = Config {
            provider: "openai".to_string(),
            language: "zh-CN".to_string(),
            llm: LLMProviders {
                openai: Some(OpenAIProvider {
                    api_key: "YOUR_OPENAI_API_KEY".to_string(),
                    api_base: Some("http://localhost:8000/v1".to_string()),
                    models: openai_models,
                    default_model: "qwen2.5-72b-instruct".to_string(),
                    proxy: None,
                }),
                gemini: Some(GeminiProvider {
                    api_key: "YOUR_GEMINI_API_KEY".to_string(),
                    models: gemini_models,
                    default_model: "gemini-2.0-flash-exp".to_string(),
                    proxy: None,
                }),
            },
        };

        let config_content = toml::to_string_pretty(&default_config)?;
        let mut file = fs::File::create(&config_path).await?;
        file.write_all(config_content.as_bytes()).await?;
        
        println!("âœ… å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {:?}", config_path);
    } else {
        println!("âš ï¸  é…ç½®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º: {:?}", config_path);
    }

    // åˆ›å»ºé»˜è®¤æç¤ºè¯æ¨¡æ¿ï¼ˆåªåœ¨ä¸å­˜åœ¨æ—¶åˆ›å»ºï¼‰
    create_default_prompts(&prompts_dir).await?;

    println!("âœ… å·²åˆ›å»ºæç¤ºè¯æ¨¡æ¿ç›®å½•: {:?}", prompts_dir);
    println!("\nğŸ“ è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œè®¾ç½®æ‚¨çš„ API å¯†é’¥:");
    println!("   {}", config_path.display());
    println!("\nğŸ’¡ æç¤ºï¼šç§æœ‰åŒ–éƒ¨ç½²æ¨¡å‹ä¼šè‡ªåŠ¨ä½¿ç”¨ 'default' é…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨æ·»åŠ æ¯ä¸ªæ¨¡å‹ã€‚");
    
    Ok(())
}

pub async fn load_config() -> Result<Config> {
    let config_dir = get_config_dir().await?;
    let config_path = config_dir.join("config.toml");

    if !config_path.exists() {
        return Err(anyhow::anyhow!(
            "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œ 'matecode init' åˆ›å»ºé»˜è®¤é…ç½®ã€‚"
        ));
    }

    let config_content = fs::read_to_string(config_path)
        .await
        .context("æ— æ³•è¯»å–é…ç½®æ–‡ä»¶")?;
    let config: Config =
        toml::from_str(&config_content).context("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯")?;

    // Validate configuration
    validate_config(&config)?;

    Ok(config)
}

fn validate_config(config: &Config) -> Result<()> {
    match config.provider.as_str() {
        "openai" => {
            if let Some(openai) = &config.llm.openai {
                if openai.api_key == "YOUR_OPENAI_API_KEY" {
                    return Err(anyhow::anyhow!(
                        "è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ OpenAI API å¯†é’¥"
                    ));
                }
            } else {
                return Err(anyhow::anyhow!(
                    "é€‰æ‹©äº† OpenAI æä¾›å•†ï¼Œä½†æœªé…ç½® OpenAI è®¾ç½®"
                ));
            }
        }
        "gemini" => {
            if let Some(gemini) = &config.llm.gemini {
                if gemini.api_key == "YOUR_GEMINI_API_KEY" {
                    return Err(anyhow::anyhow!(
                        "è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ Gemini API å¯†é’¥"
                    ));
                }
            } else {
                return Err(anyhow::anyhow!(
                    "é€‰æ‹©äº† Gemini æä¾›å•†ï¼Œä½†æœªé…ç½® Gemini è®¾ç½®"
                ));
            }
        }
        _ => {
            return Err(anyhow::anyhow!(
                "ä¸æ”¯æŒçš„ LLM æä¾›å•†: {}",
                config.provider
            ));
        }
    }
    Ok(())
}

async fn create_default_prompts(prompts_dir: &PathBuf) -> Result<()> {
    // å®šä¹‰æ‰€æœ‰æç¤ºè¯æ¨¡æ¿
    let prompt_templates = vec![
        ("commit.toml", get_commit_prompt_template()),
        ("review.toml", get_review_prompt_template()),
        ("report.toml", get_report_prompt_template()),
        ("summarize.toml", get_summarize_prompt_template()),
        ("combine.toml", get_combine_prompt_template()),
    ];

    for (filename, content) in prompt_templates {
        let file_path = prompts_dir.join(filename);
        
        // åªåœ¨æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ‰åˆ›å»º
        if !file_path.exists() {
            fs::write(&file_path, content).await?;
            println!("âœ… å·²åˆ›å»ºæç¤ºè¯æ¨¡æ¿: {:?}", file_path);
        } else {
            println!("âš ï¸  æç¤ºè¯æ¨¡æ¿å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º: {:?}", file_path);
        }
    }

    Ok(())
}

fn get_commit_prompt_template() -> &'static str {
    r#"[system]
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Git commit message ç¼–å†™ä¸“å®¶ï¼Œä½ çš„ç›®æ ‡æ˜¯ç”Ÿæˆè¯»èµ·æ¥åƒäººç±»å·¥ç¨‹å¸ˆç¼–å†™çš„ commit messageã€‚ä½ çš„å›åº”**åªèƒ½**åŒ…å« commit message å†…å®¹ï¼Œä¸è¦æœ‰å…¶ä»–ä»»ä½•è§£é‡Šã€‚ä¸¥æ ¼éµå®ˆ Conventional Commits è§„èŒƒï¼Œä½†æè¿°éƒ¨åˆ†ä½¿ç”¨ä¸­æ–‡ã€‚

[user]
è¯·æ ¹æ®ä»¥ä¸‹çš„é¡¹ç›®ä¸Šä¸‹æ–‡å’Œ git diff å†…å®¹ç”Ÿæˆä¸€ä¸ªä¸­æ–‡ git commit messageã€‚

<project_context>
{project_tree}

æœ¬æ¬¡ä¿®æ”¹å½±å“çš„æ–‡ä»¶ ({total_files} ä¸ª):
{affected_files}
</project_context>

<rules>
1.  **Header (ç¬¬ä¸€è¡Œ)**:
    -   `type` ä½¿ç”¨è‹±æ–‡ (å¦‚ feat, fix, chore)ã€‚
    -   `scope` (å¯é€‰) æ¦‚æ‹¬å˜æ›´æ¶‰åŠçš„æ¨¡å—ã€‚
    -   `subject` (ä¸»é¢˜) å¿…é¡»ç”¨æ¸…æ™°çš„ä¸­æ–‡ç®€æ˜æ‰¼è¦åœ°æè¿°å˜æ›´å†…å®¹ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ã€‚
2.  **Body (æ­£æ–‡, å¯é€‰)**:
    -   æ­£æ–‡åº”è¯¦ç»†è§£é‡Š **ä¸ºä»€ä¹ˆ** éœ€è¦è¿™æ¬¡å˜æ›´ï¼Œè§£å†³äº†ä»€ä¹ˆé—®é¢˜ã€‚
    -   æè¿°è¿™æ¬¡å˜æ›´æ˜¯ **å¦‚ä½•** å®ç°çš„ï¼Œç‰¹åˆ«æ˜¯å…³é”®çš„å®ç°æ€è·¯ã€‚
    -   é¿å…ä½¿ç”¨AIåŒ–çš„ã€è¿‡äºæ­£å¼çš„è¯­è¨€ï¼ˆä¾‹å¦‚ï¼Œä¸è¦å†™ "æœ¬æ¬¡æäº¤æ–°å¢äº†..."ï¼Œè€Œåº”è¯¥æ›´ç›´æ¥åœ°æè¿°ï¼‰ã€‚
3.  **è¾“å‡º**: åªè¾“å‡ºè¢« <commit_message> æ ‡ç­¾åŒ…è£¹çš„ commit messageã€‚
</rules>

<example_good>
<commit_message>
feat(api): å®ç°ç”¨æˆ·è®¤è¯åŠŸèƒ½

ç”¨æˆ·è®¤è¯æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒå®‰å…¨ä¿éšœã€‚æœ¬æ¬¡æäº¤å¼•å…¥äº†åŸºäº JWT çš„è®¤è¯æœºåˆ¶ã€‚
- ä½¿ç”¨ `jsonwebtoken` åº“ç”Ÿæˆå’ŒéªŒè¯ tokenã€‚
- åœ¨ `auth` ä¸­é—´ä»¶ä¸­å®ç° token æ ¡éªŒé€»è¾‘ã€‚
</commit_message>
</example_good>

<diff_content>
{diff_content}
</diff_content>
"#
}

fn get_review_prompt_template() -> &'static str {
    r#"[system]
You are an expert code reviewer. Your task is to analyze a git diff and provide constructive feedback. Focus on identifying potential bugs, improving code quality, and ensuring best practices are followed. Be clear, concise, and provide actionable suggestions. Structure your review in Markdown format.

[user]
Please review the following code changes provided in the git diff format.

## Git Diff:
```diff
{diff_content}
```

## Review Guidelines:
1.  **Overall Assessment:** Start with a brief, high-level summary of the changes.
2.  **Identify Issues and Suggestions:** For each file, provide specific feedback. Refer to line numbers where possible.
    -   **[Logic]**: Potential bugs, race conditions, or logic errors.
    -   **[Style]**: Code style, naming conventions, readability.
    -   **[Best Practice]**: Suggestions for using language features or libraries more effectively.
    -   **[Comment]**: Questions or requests for clarification.
3.  **Use Markdown:** Structure the review using headings for each file and bullet points for individual comments.
4.  **Be Constructive:** Frame your feedback positively. The goal is to help improve the code, not to criticize.
5.  **Language**: The review should be in Chinese.

## Example Output:

### `src/main.rs`
- **[Logic] at line 42:** The current logic might not handle empty input gracefully. Consider adding a check at the beginning of the function.
- **[Style] at line 55:** The variable `temp_data` could be renamed to `user_profile` for better clarity.

### `src/utils.rs`
- **[Best Practice] at line 12:** Instead of manually building the path string, consider using `PathBuf::join()` for better cross-platform compatibility.

Please provide your review for the provided diff.
"#
}

fn get_report_prompt_template() -> &'static str {
    r#"[system]
You are a senior project manager responsible for writing concise, clear, and insightful work summaries. Your goal is to synthesize a list of raw git commit messages from multiple projects into a unified report that is easy for stakeholders to understand. Group related items, use clear headings, and focus on the accomplishments and outcomes, not just the raw commit messages.

[user]
Please generate a work summary report in Markdown format based on the following commit messages from {start_date} to {end_date}.
The commits are grouped by project.

## Raw Commits:
{commits}

## Instructions:
1.  **Analyze and Group:** Read through all the commit messages from all projects. Group them into logical categories (e.g., "Feature Development," "Bug Fixes," "Refactoring").
2.  **Summarize Each Group:** For each category, write a high-level summary of the work accomplished. Use bullet points to list the key changes. **Crucially, you must mention which project the change belongs to.**
3.  **Use Clear Headings:** Use Markdown headings (e.g., `### âœ¨ æ–°åŠŸèƒ½`) for each category.
4.  **Focus on Impact:** Rephrase the commit messages to focus on the "what" and "why."
5.  **Language:** The report should be in Chinese.

## Desired Output Format:

### âœ¨ æ–°åŠŸèƒ½
- [é¡¹ç›®A] - å®ç°ç”¨æˆ·ç™»å½•å’Œæ³¨å†ŒåŠŸèƒ½ã€‚
- [é¡¹ç›®B] - æ–°å¢äº†æ•°æ®å¯¼å‡ºçš„ API.

### ğŸ› é—®é¢˜ä¿®å¤
- [é¡¹ç›®A] - ä¿®å¤äº†ç‰¹å®šåœºæ™¯ä¸‹é—ªé€€çš„é—®é¢˜ã€‚

Please generate the report now.
"#
}

fn get_summarize_prompt_template() -> &'static str {
    r#"[system]
ä½ æ˜¯ä¸€ä¸ªä»£ç å˜æ›´åˆ†æä¸“å®¶ã€‚ä½ éœ€è¦ç®€æ´åœ°æ€»ç»“è¿™ä¸ªä»£ç å—çš„ä¸»è¦å˜æ›´å†…å®¹ã€‚ä½ çš„å›åº”**åªèƒ½**åŒ…å«è¢« <summary> æ ‡ç­¾åŒ…è£¹çš„æ‘˜è¦ã€‚

[user]
è¯·åˆ†æä»¥ä¸‹ä»£ç å˜æ›´å¹¶ç”Ÿæˆç®€æ´çš„ä¸­æ–‡æ‘˜è¦ã€‚

<context>
é¡¹ç›®æ–‡ä»¶æ•°: {total_files}
æ¶‰åŠæ–‡ä»¶: {chunk_files}
</context>

<diff>
{diff_content}
</diff>

è¯·ç”¨ä¸­æ–‡æ€»ç»“è¿™ä¸ªä»£ç å—çš„ä¸»è¦å˜æ›´ï¼Œé‡ç‚¹å…³æ³¨åŠŸèƒ½æ€§æ”¹å˜ã€‚
**æ³¨æ„**ï¼šåªéœ€è¦æè¿°å˜æ›´å†…å®¹ï¼Œä¸è¦ç”Ÿæˆå®Œæ•´çš„commit messageæ ¼å¼ã€‚

ä¾‹å¦‚:
<summary>
æ·»åŠ äº†ç”¨æˆ·è®¤è¯æ¨¡å—å’Œç™»å½•åŠŸèƒ½ï¼Œå¹¶é‡æ„äº†æ•°æ®åº“è¿æ¥é€»è¾‘ã€‚
</summary>
"#
}

fn get_combine_prompt_template() -> &'static str {
    r#"[system]
ä½ æ˜¯ä¸€ä¸ªæ ¹æ®ä»£ç å˜æ›´æ‘˜è¦ç”Ÿæˆ Conventional Commits è§„èŒƒçš„ git commit message çš„ä¸“å®¶ã€‚ä½ çš„å›åº”åº”è¯¥**åªèƒ½**åŒ…å«è¢« <commit_message> æ ‡ç­¾åŒ…è£¹çš„ commit messageï¼Œä¸åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–å¼•è¨€ã€‚

[user]
è¯·æ ¹æ®ä»¥ä¸‹çš„é¡¹ç›®ä¸Šä¸‹æ–‡å’Œä»£ç å˜æ›´æ‘˜è¦ï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„ã€äººç±»å¯è¯»çš„ä¸­æ–‡ git commit messageã€‚

<project_context>
{project_tree}

æœ¬æ¬¡ä¿®æ”¹å½±å“çš„æ–‡ä»¶ ({total_files} ä¸ª):
{affected_files}
</project_context>

<summaries>
{summaries}
</summaries>

<rules>
1.  **ç›®æ ‡**: ä¸è¦åˆ›å»ºä¸€ä¸ªç®€å•çš„å˜æ›´æ—¥å¿—ã€‚ä½ çš„ç›®æ ‡æ˜¯å†™ä¸€ä¸ª**é«˜å±‚æ¬¡çš„æ€»ç»“**ï¼Œè§£é‡Šè¿™æ¬¡ç³»åˆ—å˜æ›´çš„**æ ¸å¿ƒç›®çš„**å’Œ**ä¸»è¦å®ç°**ã€‚
2.  **æ ¼å¼**: ä¸¥æ ¼éµå®ˆ Conventional Commits è§„èŒƒã€‚
3.  **è¾“å‡º**: åªè¾“å‡ºè¢« <commit_message> æ ‡ç­¾åŒ…è£¹çš„ commit messageã€‚
</rules>

<example>
<commit_message>
feat(history): å¼•å…¥æäº¤å†å²å½’æ¡£ä¸æ—¥æŠ¥ç”ŸæˆåŠŸèƒ½

ä¸ºäº†æ›´å¥½åœ°è¿½è¸ªå¼€å‘è¿›åº¦å’Œè‡ªåŠ¨åŒ–ç”Ÿæˆå·¥ä½œæŠ¥å‘Šï¼Œæœ¬æ¬¡å¼•å…¥äº†æäº¤å†å²çš„è‡ªåŠ¨å½’æ¡£æœºåˆ¶ã€‚

æ­¤åŠŸèƒ½é€šè¿‡ `post-commit` Git é’©å­å®ç°ï¼Œç¡®ä¿åªæœ‰æœ€ç»ˆè¢«é‡‡çº³çš„ commit æ‰ä¼šè¢«è®°å½•ã€‚æ–°å¢çš„ `report` å‘½ä»¤å¯ä»¥è°ƒç”¨ AI æœåŠ¡ï¼Œå°†æ¯æ—¥çš„æäº¤è®°å½•æ™ºèƒ½åœ°æ±‡æ€»æˆä¸€ä»½ç»“æ„åŒ–çš„å·¥ä½œæ—¥æŠ¥ã€‚
</commit_message>
</example>
"#
}

pub async fn get_prompt_template(name: &str) -> Result<String> {
    let config_dir = get_config_dir().await?;
    let prompt_path = config_dir.join("prompts").join(format!("{}.toml", name));
    
    if !prompt_path.exists() {
        return Err(anyhow::anyhow!(
            "æç¤ºè¯æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {}ã€‚è¯·è¿è¡Œ 'matecode init' é‡æ–°åˆ›å»ºã€‚",
            prompt_path.display()
        ));
    }

    let content = fs::read_to_string(prompt_path).await?;
    Ok(content)
}
