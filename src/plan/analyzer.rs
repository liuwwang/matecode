use super::{ProjectContext, ProjectStructure, FileContext};
use crate::config;
use crate::git;

use anyhow::Result;
use ignore::WalkBuilder;
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use tokio::fs;

/// é¡¹ç›®åˆ†æå™¨
pub struct ProjectAnalyzer {
    root_path: PathBuf,
    file_cache: HashMap<String, String>,
}

impl ProjectAnalyzer {
    pub async fn new() -> Result<Self> {
        let root_path = std::env::current_dir()?;

        Ok(Self {
            root_path,
            file_cache: HashMap::new(),
        })
    }
    
    /// åˆ†ææ•´ä¸ªä»£ç åº“
    pub async fn analyze_codebase(&self) -> Result<ProjectContext> {
        // 1. æ‰«æé¡¹ç›®ç»“æ„
        let structure = self.scan_project_structure().await?;

        // 2. è¯†åˆ«è¯­è¨€å’Œæ¡†æ¶
        let (language, framework) = self.detect_language_and_framework(&structure).await?;

        // 3. åˆ†æå…³é”®æ–‡ä»¶
        let key_files = self.analyze_key_files(&structure).await?;

        // 4. ç”Ÿæˆæ¶æ„è¯´æ˜ï¼ˆåŒ…å«é¡¹ç›®æ ‘ï¼‰
        let project_tree = self.generate_project_tree().await?;
        let architecture_notes = format!(
            "{}\n\n{}",
            self.generate_architecture_notes(&structure, &key_files).await?,
            project_tree
        );

        Ok(ProjectContext {
            language,
            framework,
            structure,
            key_files,
            architecture_notes,
        })
    }
    
    /// æ‰«æé¡¹ç›®ç»“æ„
    async fn scan_project_structure(&self) -> Result<ProjectStructure> {
        let mut directories = Vec::new();
        let mut entry_points = Vec::new();
        let mut patterns = Vec::new();

        // ä½¿ç”¨ ignore::WalkBuilder æ¥æ­£ç¡®å¤„ç† .gitignore æ–‡ä»¶
        let walker = WalkBuilder::new(&self.root_path)
            .max_depth(Some(3))
            .build();

        for result in walker {
            let entry = result?;
            let path = entry.path();

            // è·³è¿‡é¡¹ç›®æ ¹ç›®å½•æœ¬èº«
            if path == self.root_path {
                continue;
            }

            let relative_path = path.strip_prefix(&self.root_path)?;

            if path.is_dir() {
                let dir_str = relative_path.to_string_lossy().to_string();
                if !dir_str.is_empty() {
                    directories.push(dir_str);
                }
            } else if self.is_entry_point(path) {
                let entry_str = relative_path.to_string_lossy().to_string();
                entry_points.push(entry_str);
            }
        }

        // è¯†åˆ«æ¶æ„æ¨¡å¼
        patterns = self.identify_patterns(&directories);

        Ok(ProjectStructure {
            directories,
            patterns,
            entry_points,
        })
    }

    /// ç”Ÿæˆé¡¹ç›®æ–‡ä»¶æ ‘
    pub async fn generate_project_tree(&self) -> Result<String> {
        let mut tree_lines = Vec::new();
        let mut file_count = 0;

        // ä½¿ç”¨ WalkBuilder éå†é¡¹ç›®æ–‡ä»¶
        let walker = WalkBuilder::new(&self.root_path)
            .max_depth(Some(4)) // ç¨å¾®æ·±ä¸€ç‚¹ä»¥è·å–æ›´å¤šä¿¡æ¯
            .build();

        let mut entries: Vec<_> = walker.collect::<Result<Vec<_>, _>>()?;

        // æŒ‰è·¯å¾„æ’åº
        entries.sort_by(|a, b| a.path().cmp(b.path()));

        for entry in entries {
            let path = entry.path();

            // è·³è¿‡é¡¹ç›®æ ¹ç›®å½•æœ¬èº«
            if path == self.root_path {
                continue;
            }

            if let Ok(relative_path) = path.strip_prefix(&self.root_path) {
                let path_str = relative_path.to_string_lossy();
                let depth = relative_path.components().count();

                // ç”Ÿæˆç¼©è¿›
                let indent = "  ".repeat(depth.saturating_sub(1));
                let prefix = if path.is_dir() { "ğŸ“" } else { "ğŸ“„" };

                if let Some(file_name) = relative_path.file_name() {
                    tree_lines.push(format!("{}{} {}", indent, prefix, file_name.to_string_lossy()));
                    if path.is_file() {
                        file_count += 1;
                    }
                }
            }
        }

        // é™åˆ¶è¾“å‡ºé•¿åº¦ä»¥é¿å… token é™åˆ¶
        if tree_lines.len() > 100 {
            tree_lines.truncate(100);
            tree_lines.push("... (æ›´å¤šæ–‡ä»¶å·²çœç•¥)".to_string());
        }

        let tree_content = tree_lines.join("\n");
        let header = format!("é¡¹ç›®æ–‡ä»¶æ ‘ (å…± {} ä¸ªæ–‡ä»¶):\n", file_count);

        Ok(format!("{}{}", header, tree_content))
    }
    

    
    /// æ£€æŸ¥æ˜¯å¦æ˜¯å…¥å£æ–‡ä»¶
    fn is_entry_point(&self, path: &Path) -> bool {
        if let Some(file_name) = path.file_name().and_then(|n| n.to_str()) {
            matches!(file_name, 
                "main.rs" | "lib.rs" | "mod.rs" |
                "main.py" | "__init__.py" |
                "index.js" | "app.js" | "server.js" |
                "main.go" | "main.java" |
                "App.tsx" | "index.tsx"
            )
        } else {
            false
        }
    }
    
    /// è¯†åˆ«æ¶æ„æ¨¡å¼
    fn identify_patterns(&self, directories: &[String]) -> Vec<String> {
        let mut patterns = Vec::new();
        
        // æ£€æŸ¥å¸¸è§çš„æ¶æ„æ¨¡å¼
        if directories.iter().any(|d| d.contains("src/commands")) {
            patterns.push("Command Pattern".to_string());
        }
        if directories.iter().any(|d| d.contains("src/models") || d.contains("models/")) {
            patterns.push("MVC Pattern".to_string());
        }
        if directories.iter().any(|d| d.contains("src/services") || d.contains("services/")) {
            patterns.push("Service Layer".to_string());
        }
        if directories.iter().any(|d| d.contains("components/")) {
            patterns.push("Component-Based".to_string());
        }
        
        patterns
    }
    
    /// æ£€æµ‹è¯­è¨€å’Œæ¡†æ¶
    async fn detect_language_and_framework(&self, _structure: &ProjectStructure) -> Result<(String, Option<String>)> {
        // æ£€æŸ¥é…ç½®æ–‡ä»¶æ¥ç¡®å®šè¯­è¨€å’Œæ¡†æ¶
        let config_files = [
            ("Cargo.toml", "rust", Some("cargo")),
            ("package.json", "javascript", None),
            ("requirements.txt", "python", None),
            ("go.mod", "go", None),
            ("pom.xml", "java", Some("maven")),
        ];
        
        for (file, lang, framework) in config_files {
            let file_path = self.root_path.join(file);
            if file_path.exists() {
                // è¿›ä¸€æ­¥æ£€æµ‹æ¡†æ¶
                let detected_framework = if let Some(fw) = framework {
                    Some(fw.to_string())
                } else {
                    self.detect_framework(lang, &file_path).await?
                };
                
                return Ok((lang.to_string(), detected_framework));
            }
        }
        
        Ok(("unknown".to_string(), None))
    }
    
    /// æ£€æµ‹å…·ä½“æ¡†æ¶
    async fn detect_framework(&self, language: &str, config_file: &Path) -> Result<Option<String>> {
        let content = fs::read_to_string(config_file).await?;
        
        match language {
            "javascript" => {
                if content.contains("\"react\"") {
                    Ok(Some("react".to_string()))
                } else if content.contains("\"express\"") {
                    Ok(Some("express".to_string()))
                } else if content.contains("\"next\"") {
                    Ok(Some("nextjs".to_string()))
                } else {
                    Ok(None)
                }
            }
            "rust" => {
                if content.contains("actix-web") {
                    Ok(Some("actix-web".to_string()))
                } else if content.contains("axum") {
                    Ok(Some("axum".to_string()))
                } else if content.contains("rocket") {
                    Ok(Some("rocket".to_string()))
                } else {
                    Ok(None)
                }
            }
            "python" => {
                if content.contains("django") {
                    Ok(Some("django".to_string()))
                } else if content.contains("flask") {
                    Ok(Some("flask".to_string()))
                } else if content.contains("fastapi") {
                    Ok(Some("fastapi".to_string()))
                } else {
                    Ok(None)
                }
            }
            _ => Ok(None),
        }
    }
    
    /// åˆ†æå…³é”®æ–‡ä»¶
    async fn analyze_key_files(&self, structure: &ProjectStructure) -> Result<Vec<FileContext>> {
        let mut key_files = Vec::new();
        
        // åˆ†æå…¥å£æ–‡ä»¶
        for entry_point in &structure.entry_points {
            let file_path = self.root_path.join(entry_point);
            if let Ok(context) = self.analyze_single_file(&file_path).await {
                key_files.push(context);
            }
        }
        
        // åˆ†æé…ç½®æ–‡ä»¶
        let config_files = ["Cargo.toml", "package.json", "requirements.txt"];
        for config_file in config_files {
            let file_path = self.root_path.join(config_file);
            if file_path.exists() {
                if let Ok(context) = self.analyze_single_file(&file_path).await {
                    key_files.push(context);
                }
            }
        }
        
        Ok(key_files)
    }
    
    /// åˆ†æå•ä¸ªæ–‡ä»¶
    async fn analyze_single_file(&self, file_path: &Path) -> Result<FileContext> {
        let content = fs::read_to_string(file_path).await?;
        let relative_path = file_path.strip_prefix(&self.root_path)?;
        
        // è¿™é‡Œå¯ä»¥ä½¿ç”¨ LLM æ¥åˆ†ææ–‡ä»¶å†…å®¹ï¼Œç”Ÿæˆæ‘˜è¦
        // ä¸ºäº†ç®€åŒ–ï¼Œå…ˆä½¿ç”¨åŸºæœ¬çš„åˆ†æ
        let summary = self.generate_file_summary(&content, file_path).await?;
        let key_functions = self.extract_key_functions(&content, file_path);
        let dependencies = self.extract_dependencies(&content, file_path);
        
        Ok(FileContext {
            path: relative_path.to_string_lossy().to_string(),
            summary,
            key_functions,
            dependencies,
        })
    }
    
    /// ç”Ÿæˆæ–‡ä»¶æ‘˜è¦
    async fn generate_file_summary(&self, content: &str, file_path: &Path) -> Result<String> {
        // å¦‚æœæ–‡ä»¶å¤ªå¤§ï¼Œå®‰å…¨åœ°æˆªå–å‰1000ä¸ªå­—ç¬¦ï¼ˆè€ƒè™‘å­—ç¬¦è¾¹ç•Œï¼‰
        let _content_preview = if content.len() > 1000 {
            // æ‰¾åˆ°å®‰å…¨çš„å­—ç¬¦è¾¹ç•Œ
            let mut boundary = 1000;
            while boundary > 0 && !content.is_char_boundary(boundary) {
                boundary -= 1;
            }
            &content[..boundary]
        } else {
            content
        };
        
        // åŸºäºæ–‡ä»¶æ‰©å±•åå’Œå†…å®¹ç”Ÿæˆç®€å•æ‘˜è¦
        if let Some(ext) = file_path.extension().and_then(|e| e.to_str()) {
            match ext {
                "rs" => Ok(format!("Rustæºæ–‡ä»¶ï¼ŒåŒ…å«{}è¡Œä»£ç ", content.lines().count())),
                "js" | "ts" => Ok(format!("JavaScript/TypeScriptæ–‡ä»¶ï¼ŒåŒ…å«{}è¡Œä»£ç ", content.lines().count())),
                "py" => Ok(format!("Pythonæ–‡ä»¶ï¼ŒåŒ…å«{}è¡Œä»£ç ", content.lines().count())),
                "toml" | "json" => Ok("é…ç½®æ–‡ä»¶".to_string()),
                _ => Ok(format!("æ–‡ä»¶ç±»å‹: {}", ext)),
            }
        } else {
            Ok("æœªçŸ¥æ–‡ä»¶ç±»å‹".to_string())
        }
    }
    
    /// æå–å…³é”®å‡½æ•°
    fn extract_key_functions(&self, content: &str, file_path: &Path) -> Vec<String> {
        let mut functions = Vec::new();
        
        if let Some(ext) = file_path.extension().and_then(|e| e.to_str()) {
            match ext {
                "rs" => {
                    // ç®€å•çš„ Rust å‡½æ•°æå–
                    for line in content.lines() {
                        if line.trim().starts_with("pub fn ") || line.trim().starts_with("fn ") {
                            if let Some(func_name) = line.split_whitespace().nth(1) {
                                functions.push(func_name.split('(').next().unwrap_or(func_name).to_string());
                            }
                        }
                    }
                }
                "js" | "ts" => {
                    // ç®€å•çš„ JavaScript å‡½æ•°æå–
                    for line in content.lines() {
                        if line.contains("function ") || line.contains("const ") && line.contains("=>") {
                            // ç®€åŒ–çš„å‡½æ•°åæå–
                            functions.push("JavaScriptå‡½æ•°".to_string());
                        }
                    }
                }
                _ => {}
            }
        }
        
        functions
    }
    
    /// æå–ä¾èµ–å…³ç³»
    fn extract_dependencies(&self, content: &str, file_path: &Path) -> Vec<String> {
        let mut dependencies = Vec::new();
        
        // æå– import/use è¯­å¥
        for line in content.lines() {
            let trimmed = line.trim();
            if trimmed.starts_with("use ") || trimmed.starts_with("import ") {
                dependencies.push(trimmed.to_string());
            }
        }
        
        dependencies
    }
    
    /// ç”Ÿæˆæ¶æ„è¯´æ˜
    async fn generate_architecture_notes(&self, structure: &ProjectStructure, key_files: &[FileContext]) -> Result<String> {
        let mut notes = String::new();
        
        notes.push_str(&format!("é¡¹ç›®åŒ…å« {} ä¸ªç›®å½•ï¼Œ", structure.directories.len()));
        notes.push_str(&format!("{} ä¸ªå…¥å£æ–‡ä»¶ã€‚", structure.entry_points.len()));
        
        if !structure.patterns.is_empty() {
            notes.push_str(&format!("\nè¯†åˆ«çš„æ¶æ„æ¨¡å¼: {}", structure.patterns.join(", ")));
        }
        
        notes.push_str(&format!("\nå…³é”®æ–‡ä»¶æ•°é‡: {}", key_files.len()));
        
        Ok(notes)
    }
    
    /// æ ¹æ®éœ€æ±‚æè¿°æ‰¾åˆ°ç›¸å…³æ–‡ä»¶
    pub async fn find_related_files(&self, description: &str) -> Result<Vec<FileContext>> {
        // è¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´æ™ºèƒ½çš„æ–¹æ³•ï¼Œæ¯”å¦‚å‘é‡æœç´¢
        // ç°åœ¨å…ˆä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…
        let key_files = self.analyze_key_files(&self.scan_project_structure().await?).await?;

        // ç®€å•çš„å…³é”®è¯åŒ¹é…
        let related_files = key_files.into_iter()
            .filter(|file| {
                description.to_lowercase().contains("auth") && file.path.contains("auth") ||
                description.to_lowercase().contains("user") && file.path.contains("user") ||
                description.to_lowercase().contains("api") && file.path.contains("api")
            })
            .collect();

        Ok(related_files)
    }

    /// è·å–å‹ç¼©çš„é¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå¤„ç† token é™åˆ¶ï¼‰
    pub async fn get_compressed_context(&self, max_files: usize) -> Result<ProjectContext> {
        let mut context = self.analyze_codebase().await?;

        // é™åˆ¶å…³é”®æ–‡ä»¶æ•°é‡
        if context.key_files.len() > max_files {
            context.key_files.truncate(max_files);
        }

        // å‹ç¼©æ¶æ„è¯´æ˜
        if context.architecture_notes.len() > 500 {
            context.architecture_notes = format!("{}...(å·²å‹ç¼©)", &context.architecture_notes[..500]);
        }

        // é™åˆ¶ç›®å½•æ•°é‡
        if context.structure.directories.len() > 20 {
            context.structure.directories.truncate(20);
        }

        Ok(context)
    }

    /// è·å–ç²¾ç®€çš„ç›¸å…³æ–‡ä»¶åˆ—è¡¨
    pub async fn get_essential_related_files(&self, description: &str, max_files: usize) -> Result<Vec<FileContext>> {
        let mut related_files = self.find_related_files(description).await?;

        // é™åˆ¶æ–‡ä»¶æ•°é‡
        if related_files.len() > max_files {
            related_files.truncate(max_files);
        }

        // å‹ç¼©æ–‡ä»¶æ‘˜è¦
        for file in &mut related_files {
            if file.summary.len() > 200 {
                file.summary = format!("{}...", &file.summary[..200]);
            }

            // é™åˆ¶å‡½æ•°åˆ—è¡¨
            if file.key_functions.len() > 5 {
                file.key_functions.truncate(5);
            }

            // é™åˆ¶ä¾èµ–åˆ—è¡¨
            if file.dependencies.len() > 3 {
                file.dependencies.truncate(3);
            }
        }

        Ok(related_files)
    }
}
