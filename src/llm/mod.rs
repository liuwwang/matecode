//! src/llm/mod.rs

use anyhow::{anyhow, Result};
use async_trait::async_trait;
use colored::Colorize;

pub mod gemini;
pub mod openai;

pub use gemini::GeminiClient;
pub use openai::OpenClient;

/// The `LLMClient` trait defines the interface for a Large Language Model client.
#[async_trait]
pub trait LLMClient: Send + Sync {
    /// Returns the name of the LLM client.
    fn name(&self) -> &str;
    /// Calls the LLM with a user prompt and returns the generated response.
    async fn call(&self, user_prompt: &str) -> Result<String>;
}

pub enum LLM {
    Gemini(GeminiClient),
    OpenAI(OpenClient),
}

#[async_trait]
impl LLMClient for LLM {
    fn name(&self) -> &str {
        match self {
            LLM::Gemini(c) => c.name(),
            LLM::OpenAI(c) => c.name(),
        }
    }

    async fn call(&self, user_prompt: &str) -> Result<String> {
        match self {
            LLM::Gemini(c) => c.call(user_prompt).await,
            LLM::OpenAI(c) => c.call(user_prompt).await,
        }
    }
}

pub fn extract_content(text: &str, tag: &str) -> Option<String> {
    let start_tag = format!("<{tag}>");
    let end_tag = format!("</{tag}>");
    let start_byte = text.find(&start_tag)? + start_tag.len();
    text[start_byte..]
        .find(&end_tag)
        .map(|end| text[start_byte..start_byte + end].to_string())
        .map(|s| s.trim().to_string())
}

pub async fn generate_commit_message(client: &LLM, diff: &str) -> Result<String> {
    println!("ğŸ¤– æ­£åœ¨è°ƒç”¨ {} ç”Ÿæˆæäº¤ä¿¡æ¯...", client.name());

    let system_prompt = r#"ä½ æ˜¯ä¸€ä¸ªæ ¹æ® git diff å†…å®¹ç”Ÿæˆ Conventional Commits è§„èŒƒçš„ git commit message çš„ä¸“å®¶ã€‚ä½ çš„å›åº”åº”è¯¥åªåŒ…å« commit messageï¼Œä¸åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–å¼•è¨€ã€‚commit message åº”è¯¥æ˜¯ markdown æ ¼å¼ï¼Œä»¥`#`å¼€å¤´ã€‚"#;

    let user_prompt = format!(
        r#"è¯·æ ¹æ®ä»¥ä¸‹çš„ git diff å†…å®¹ç”Ÿæˆä¸€ä¸ª git commit messageã€‚
<rules>
1. ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Git commit message ç¼–å†™ä¸“å®¶ã€‚
2. ä½ çš„å›åº”**åªèƒ½**åŒ…å« commit message å†…å®¹ï¼Œä¸è¦æœ‰å…¶ä»–ä»»ä½•è§£é‡Šã€‚
3. commit message å¿…é¡»ä¸¥æ ¼éµå®ˆ Conventional Commits è§„èŒƒã€‚
4. commit message çš„ header éƒ¨åˆ†(ç¬¬ä¸€è¡Œ)ä¸èƒ½è¶…è¿‡ 50 ä¸ªå­—ç¬¦ã€‚
5. commit message çš„ subject åº”è¯¥æ¸…æ™°åœ°æè¿°è¿™æ¬¡æäº¤çš„ç›®çš„ã€‚
6. å¦‚æœæœ‰ scopeï¼Œè¯·åœ¨ type åç”¨æ‹¬å·é™„ä¸Šï¼Œä¾‹å¦‚ `feat(api):`ã€‚
7. æ ¹æ®ä¸‹é¢çš„ `<diff>` å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªåˆé€‚çš„ commit messageã€‚
</rules>
<diff>
{}
</diff>"#,
        diff
    );

    let raw_llm_output = client.call(&user_prompt).await?;

    if let Some(thought) = extract_content(&raw_llm_output, "think") {
        println!(
            "\nğŸ¤” {}{}\n",
            "AI æ€è€ƒ:".bold(),
            format!("\n---\n{}\n---", thought).cyan()
        );
    }

    let commit_message = extract_content(&raw_llm_output, "commit_message").ok_or_else(|| {
        anyhow!(
            "æ— æ³•ä» LLM å“åº”ä¸­æå– <commit_message> æ ‡ç­¾ã€‚\nåŸå§‹è¾“å‡º: {}",
            raw_llm_output
        )
    })?;

    Ok(commit_message)
}
